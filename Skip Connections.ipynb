{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [All you need to know about skip connections](https://www.analyticsvidhya.com/blog/2021/08/all-you-need-to-know-about-skip-connections/)\n",
    "Skip connections allow us to overcome the degradation problem/vanishing gradients problem where deep networks begin to perform worse than shallow networks. As the network gets deeper it become hard (read, impossible) for the weights to be propagated back to the earlier layers. Skip connections allow us to pass these weights forward from earlier layers to later layers allowing more fine grained detail to remain in the network at the end alongside more abstracted features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet - A residual block\n",
    "First we implement a residual block using skip connections in PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "\n",
    "# basic resdidual block of ResNet\n",
    "# This is generic in the sense, it could be used for downsampling of features.\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=[1, 1], downsample=None):\n",
    "        \"\"\"\n",
    "        A basic residual block of ResNet\n",
    "        Parameters\n",
    "        ----------\n",
    "            in_channels: Number of channels that the input have\n",
    "            out_channels: Number of channels that the output have\n",
    "            stride: strides in convolutional layers\n",
    "            downsample: A callable to be applied before addition of residual mapping\n",
    "        \"\"\"\n",
    "        super(ResidualBlock, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels, out_channels, kernel_size=3, stride=stride[0], \n",
    "            padding=1, bias=False\n",
    "        )\n",
    "\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            out_channels, out_channels, kernel_size=3, stride=stride[1], \n",
    "            padding=1, bias=False\n",
    "        )\n",
    "\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "        self.downsample = downsample\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        # applying a downsample function before adding it to the output\n",
    "        if(self.downsample is not None):\n",
    "            residual = downsample(residual)\n",
    "\n",
    "        out = F.relu(self.bn(self.conv1(x)))\n",
    "        \n",
    "        out = self.bn(self.conv2(out))\n",
    "        # note that adding residual before activation \n",
    "        out = out + residual\n",
    "        out = F.relu(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 128, 13, 13])\n"
     ]
    }
   ],
   "source": [
    "# downsample using 1*1 convolution\n",
    "downsample = nn.Sequential(\n",
    "    nn.Conv2d(64, 128, kernel_size=1, stride=2, bias=False),\n",
    "    nn.BatchNorm2d(128)\n",
    ")\n",
    "# First 5 layers of ResNet34\n",
    "resnet_blocks = nn.Sequential(\n",
    "    nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False),\n",
    "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "    ResidualBlock(64,64),\n",
    "    ResidualBlock(64,64),\n",
    "    ResidualBlock(64,128, stride=[2,1], downsample=downsample)\n",
    ")\n",
    "\n",
    "# checking the shape\n",
    "inputs = torch.rand(1,3,100,100) # single 100*100 colour image\n",
    "outputs = resnet_blocks(inputs)\n",
    "print(outputs.shape) # shape would be (1,128,13,13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one could also use pretrained weight of ResNet trained on ImageNet\n",
    "resnet34 = torchvision.models.resnet34(pretrained=True)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "30b2d88519b42e2b1be5e12579ff4b114f9834f469b31be7f82137c9c3522cd2"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('Testing': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
